{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import pickle\n",
    "import gzip\n",
    "# hidden : [neurons of each specific layer]\n",
    "# Neural Network Components\n",
    "\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import pickle as pk\n",
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self, size_in, size_out, hidden, rate = 0.001, w_decay = 0, av = None, loss = None):\n",
    "        self.x = np.zeros((size_in, 1), dtype=np.float64)\n",
    "        self.y = np.zeros((size_out, 1), dtype=np.float64)\n",
    "        self.weight = []\n",
    "        self.weight_ = []\n",
    "        self.bias = []\n",
    "        self.bias_ = []\n",
    "        self.z = []\n",
    "        self.activations = []\n",
    "        \n",
    "        idx = 0\n",
    "        self.layer = len(hidden) + 1\n",
    "        n = self.layer - 1\n",
    "        self.weight.append(np.random.rand(hidden[idx], size_in) * np.sqrt(2 / size_in))\n",
    "        self.weight_.append(np.zeros((hidden[idx], size_in), dtype=np.float64))\n",
    "        self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "        self.bias_.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "        self.activations.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "        self.z.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < n:\n",
    "            self.weight.append(np.random.rand(hidden[idx], hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "            self.weight_.append(np.zeros((hidden[idx], hidden[idx - 1]), dtype=np.float64))\n",
    "            self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "            self.bias_.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "            self.z.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "            self.activations.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "            idx += 1\n",
    "        \n",
    "        self.weight.append(np.random.rand(size_out, hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "        self.weight_.append(np.zeros((size_out, hidden[idx - 1]), dtype=np.float64))\n",
    "        self.bias.append(np.random.rand(size_out, 1))\n",
    "        self.bias_.append(np.zeros((size_out, 1), dtype=np.float64))\n",
    "        self.activations.append(np.zeros((size_out, 1), dtype=np.float64))\n",
    "        self.z.append(np.zeros((size_out, 1), dtype=np.float64))\n",
    "        \n",
    "        self.rate = rate\n",
    "        self.w_decay = w_decay\n",
    "        \n",
    "        if av != None:\n",
    "            if(hasattr(av[0], '__call__') and  hasattr(av[1], '__call__')):\n",
    "                self.activate = av[0]\n",
    "                self.activate_ = av[1]\n",
    "                \n",
    "        if loss != None:\n",
    "            if(hasattr(loss[0], '__call__') and  hasattr(loss[1], '__call__')):\n",
    "                self.cost = loss[0]\n",
    "                self.cost_ = loss[1]\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return (1 - np.exp(-(x * 2))) / (1 + np.exp(-(x * 2)))\n",
    "    \n",
    "    def activate_(self, x):\n",
    "        return 1 - np.square(self.activate(x))   \n",
    "    \n",
    "    def cost(self, y):\n",
    "        return (self.y - y) ** 2\n",
    "    \n",
    "    def cost_(self, y):\n",
    "        return (self.y - y) * 2\n",
    "    \n",
    "    def feed(self, x):\n",
    "        self.x[:] = x.reshape((x.shape[0], 1))\n",
    "        idx = 0\n",
    "        n = self.layer - 1\n",
    "        self.z[idx] = self.weight[idx].dot(self.x) + self.bias[idx]\n",
    "        self.activations[idx] = self.activate(self.z[idx])\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < n:\n",
    "            self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "            self.activations[idx] = self.activate(self.z[idx])\n",
    "            idx += 1\n",
    "        \n",
    "        self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "        self.y = self.activate(self.z[idx])\n",
    "        \n",
    "    def propagate(self, y):\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        idx = self.layer - 1\n",
    "        i_ = self.activate_(self.z[idx]) * self.cost_(y)\n",
    "        self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "        self.bias_[idx] = i_\n",
    "        c_ = self.weight[idx].T.dot(i_)\n",
    "        idx -= 1\n",
    "        \n",
    "        while idx > 0:\n",
    "            i_ = self.activate_(self.z[idx]) * c_\n",
    "            self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "            self.bias_[idx] = i_\n",
    "            c_ = self.weight[idx].T.dot(i_)\n",
    "            idx -= 1\n",
    "        \n",
    "        i_ = self.activate_(self.z[idx]) * c_\n",
    "        self.weight_[idx] = i_.dot(self.x.T)\n",
    "        self.bias_[idx] = i_\n",
    "        \n",
    "        \n",
    "        while idx < self.layer:\n",
    "            self.weight_[idx] += self.weight[idx] * self.w_decay\n",
    "            w, b = self.update(self.weight_[idx], self.bias_[idx], idx)\n",
    "            self.weight[idx] -= w\n",
    "            self.bias[idx] -= b\n",
    "            idx += 1\n",
    "    \n",
    "    def update(self, w_, b_, idx):\n",
    "        return self.rate * w_, self.rate * b_\n",
    "    \n",
    "    def heetal_w(self, cur, prev, com):\n",
    "        return np.random.randn(com, cur) * np.sqrt(2 / prev)\n",
    "           \n",
    "    def result(self):\n",
    "        return self.y\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return (2 / (1 + np.exp(-2 * x))) - 1\n",
    "\n",
    "def tanh_(x):\n",
    "    return 1 - np.square(tanh(x))\n",
    "\n",
    "def relu(x, a = 0.01):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_(x, a = 0.01):\n",
    "    return 1 * (x > 0)\n",
    "    \n",
    "def soe(dif):\n",
    "    return np.square(dif)\n",
    "\n",
    "def soe_(dif):\n",
    "    return 2 * dif\n",
    "\n",
    "class AdaDelta:\n",
    "    def __init__(self, ann, arbitary = 1e-25, moment = 0.9):\n",
    "        self.epsilon = arbitary\n",
    "        self.moment = moment\n",
    "        self.rate = ann.rate\n",
    "        self.E = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        self.delta = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        ann.update = self\n",
    "        \n",
    "    def evaluate(self, w_, b_, idx):\n",
    "        self.E[0][idx] = self.moment * self.E[0][idx] + (1 - self.moment) * (w_ ** 2)\n",
    "        delta = self.rate * w_\n",
    "        delta /= np.sqrt(self.E[0][idx] + self.epsilon)\n",
    "        old_delta = self.delta[0][idx]\n",
    "        self.delta[0][idx] = self.moment * self.delta[0][idx] + (1 - self.moment) * (delta ** 2)\n",
    "        \n",
    "        self.E[1][idx] = self.moment * self.E[1][idx] + (1 - self.moment) * (b_ ** 2)\n",
    "        delta = self.rate * b_\n",
    "        delta /= np.sqrt(self.E[1][idx] + self.epsilon)\n",
    "        old_delta_b = self.delta[1][idx]\n",
    "        self.delta[1][idx] = self.moment * self.delta[1][idx] + (1 - self.moment) * (delta ** 2)\n",
    "        \n",
    "        w_rate = np.sqrt(old_delta + self.epsilon)\n",
    "        w_rate /= np.sqrt(self.E[0][idx] + self.epsilon)\n",
    "        \n",
    "        b_rate = np.sqrt(old_delta_b + self.epsilon)\n",
    "        b_rate /= np.sqrt(self.E[1][idx] + self.epsilon)\n",
    "        \n",
    "        return w_rate, b_rate\n",
    "        \n",
    "    def __call__(self, w_, b_, idx):\n",
    "        w_rate, b_rate = self.evaluate(w_, b_, idx)\n",
    "        return w_rate * w_, b_rate * b_\n",
    "            \n",
    "    def genParams(self, ann, is_weight = True):\n",
    "        l = ann.layer\n",
    "        idx = 0\n",
    "        while idx < l:\n",
    "            yield np.zeros(ann.weight_[idx].shape if is_weight else ann.bias_[idx].shape, dtype=np.float64)\n",
    "            idx += 1\n",
    "            \n",
    "class Adam:\n",
    "    def __init__(self, ann, arbitary = 1e-8, beta1 = 0.9, beta2 = 0.999):\n",
    "        self.epsilon = arbitary\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.rate = ann.rate\n",
    "        self.M = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        self.V = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        ann.update = self\n",
    "    \n",
    "    def __call__(self, w_, b_, idx):\n",
    "        self.M[0][idx] = self.beta1 * self.M[0][idx] + (1 - self.beta1) * w_\n",
    "        self.V[0][idx] = self.beta2 * self.V[0][idx] + (1 - self.beta2) * (w_ ** 2)\n",
    "        M_cup = self.M[0][idx] / (1 - self.beta1)\n",
    "        V_cup = self.V[0][idx] / (1 - self.beta2)\n",
    "        weight = self.rate * (M_cup / (np.sqrt(V_cup) + self.epsilon))\n",
    "        \n",
    "        self.M[1][idx] = self.beta1 * self.M[1][idx] + (1 - self.beta1) * b_\n",
    "        self.V[1][idx] = self.beta2 * self.V[1][idx] + (1 - self.beta2) * (b_ ** 2)\n",
    "        M_cup = self.M[1][idx] / (1 - self.beta1)\n",
    "        V_cup = self.V[1][idx] / (1 - self.beta2)\n",
    "        bias = self.rate * (M_cup / (np.sqrt(V_cup) + self.epsilon))\n",
    "        \n",
    "        return weight, bias\n",
    "            \n",
    "    def genParams(self, ann, is_weight = True):\n",
    "        l = ann.layer\n",
    "        idx = 0\n",
    "        while idx < l:\n",
    "            yield np.zeros(ann.weight_[idx].shape if is_weight else ann.bias_[idx].shape, dtype=np.float64)\n",
    "            idx += 1\n",
    "\n",
    "def train(ann, x, y, n = 1):\n",
    "    i = 0\n",
    "    epoch = 1\n",
    "    out = np.zeros(10)\n",
    "    plot_size = (x.shape[0] * n) + 1\n",
    "    costs = np.zeros(plot_size)\n",
    "    w_ = np.zeros(plot_size)\n",
    "    b_ = np.zeros(plot_size)\n",
    "    while i < n:\n",
    "        idx = x.shape[0] - 1\n",
    "        while idx > -1:\n",
    "            ann.feed(x[idx])\n",
    "            out[y[idx]] = 1\n",
    "            costs[epoch] = ann.cost(out).sum()\n",
    "            ann.propagate(out)\n",
    "            w_[epoch] = ann.weight_[2][0][0]\n",
    "            b_[epoch] = ann.bias_[2][0][0]\n",
    "            out[y[idx]] = 0\n",
    "            idx -= 1\n",
    "            epoch += 1\n",
    "        i += 1\n",
    "    return (w_, b_, costs)\n",
    "\n",
    "with gzip.open('tmp/mnist.pkl.gz', 'rb') as file:\n",
    "    train_set, valid_set, test_set = pickle.load(file, encoding='iso-8859-1')\n",
    "train_x, train_y = train_set\n",
    "valid_x, valid_y = valid_set\n",
    "test_x, test_y = test_set\n",
    "\n",
    "universe = np.arange(0, cost_tanh.size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_tanh = NeuralNet(784, 10, [25, 25])\n",
    "AdaDelta(ann_tanh)\n",
    "cost_tanh, w_tanh, b_tanh = train(ann_tanh, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_relu = NeuralNet(784, 10, [25, 25], av=(relu, relu_))\n",
    "AdaDelta(ann_relu)\n",
    "cost_relu, w_relu, b_relu = train(ann_relu, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_sig = NeuralNet(784, 10, [25, 25], av=(sigmoid, sigmoid_))\n",
    "AdaDelta(ann_sig)\n",
    "cost_sig, w_sig, b_sig = train(ann_tanh, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NavigationToolbar2TkAgg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5970e97f6239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TkAgg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_tkagg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasTkAgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNavigationToolbar2TkAgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'NavigationToolbar2TkAgg'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2TkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "universe = np.arange(0, cost_tanh.size, 1)\n",
    "\n",
    "class FixedOrderFormatter(ScalarFormatter):\n",
    "    \"\"\"Formats axis ticks using scientific notation with a constant order of \n",
    "    magnitude\"\"\"\n",
    "    def __init__(self, order_of_mag=0, useOffset=True, useMathText=False):\n",
    "        self._order_of_mag = order_of_mag\n",
    "        ScalarFormatter.__init__(self, useOffset=useOffset, \n",
    "                                 useMathText=useMathText)\n",
    "    def _set_orderOfMagnitude(self, range):\n",
    "        \"\"\"Over-riding this to avoid having orderOfMagnitude reset elsewhere\"\"\"\n",
    "        self.orderOfMagnitude = self._order_of_mag\n",
    "\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "fig = plot.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "rpr_dW = w_tanh[:60]\n",
    "rpr_dB = rate_tanh[:60]\n",
    "rpr_costs = universe[:60]\n",
    "\n",
    "for k in range(0, rpr_dW.size, 1):\n",
    "    ax.plot(rpr_dW[:k], rpr_dB[:k], rpr_costs[:k])\n",
    "    \n",
    "    #ax.set_xlim3d(-0.4, 0.4)\n",
    "    #ax.set_ylim3d(-0.4, 0.4)\n",
    "    #ax.set_zlim3d(0, 100)\n",
    "    ax.xaxis.set_label_text('dW')\n",
    "    ax.yaxis.set_label_text('rate')\n",
    "    ax.zaxis.set_label_text('Epoch')\n",
    "    ax.xaxis.label.set_fontsize(12)\n",
    "    ax.yaxis.label.set_fontsize(12)\n",
    "    ax.zaxis.label.set_fontsize(12)\n",
    "    ax.xaxis.set_major_formatter(FixedOrderFormatter(0))\n",
    "    ax.yaxis.set_major_formatter(FixedOrderFormatter(0))\n",
    "    ax.zaxis.set_major_formatter(FixedOrderFormatter(0))\n",
    "    plot.draw()\n",
    "    plot.pause(0.05)\n",
    "    if k != rpr_dW.size - 1:\n",
    "        ax.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "fig, ax= plot.subplots(nrows=1, figsize=(12, 9))\n",
    "\n",
    "ax.plot(universe[::100], cost_sig[::100], 'r', label = 'Sigmoid')\n",
    "ax.plot(universe[::100], cost_tanh[::100], 'g', label = 'Tanh')\n",
    "ax.plot(universe[::100], cost_relu[::100], 'b', label = 'ReLU')\n",
    "ax.set_title('AdaDelta Training Costs')\n",
    "ax.legend()\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.xaxis.set_label_text('Epoch')\n",
    "ax.yaxis.set_label_text('Cost')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left\n",
    "\n",
    "plot.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig('./Images/Cost Variances Through Training.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
