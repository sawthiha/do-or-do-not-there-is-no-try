{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden : [neurons of each specific layer]\n",
    "class NeuralNet:\n",
    "    def __init__(self, size_in, size_out, hidden, rate = 0.1, w_decay = 0, av = None, av_ = None, loss = None, loss_ = None):\n",
    "        self.x = np.zeros((size_in, 1), dtype=np.float64)\n",
    "        self.y = np.zeros((size_out, 1), dtype=np.float64)\n",
    "        self.weight = []\n",
    "        self.weight_ = []\n",
    "        self.bias = []\n",
    "        self.bias_ = []\n",
    "        self.z = []\n",
    "        self.activations = []\n",
    "        \n",
    "        idx = 0\n",
    "        self.layer = len(hidden) + 1\n",
    "        n = self.layer - 1\n",
    "        self.weight.append(np.random.rand(hidden[idx], size_in) * np.sqrt(2 / size_in))\n",
    "        self.weight_.append(np.zeros((hidden[idx], size_in)))\n",
    "        self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "        self.bias_.append(np.zeros((hidden[idx], 1)))\n",
    "        self.activations.append(np.zeros((hidden[idx], 1)))\n",
    "        self.z.append(np.zeros((hidden[idx], 1)))\n",
    "        \n",
    "        idx += 1\n",
    "        while idx < n:\n",
    "            self.weight.append(np.random.rand(hidden[idx], hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "            self.weight_.append(np.zeros((hidden[idx], hidden[idx - 1])))\n",
    "            self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "            self.bias_.append(np.zeros((hidden[idx], 1)))\n",
    "            self.z.append(np.zeros((hidden[idx], 1)))\n",
    "            self.activations.append(np.zeros((hidden[idx], 1)))\n",
    "            idx += 1\n",
    "        \n",
    "        self.weight.append(np.random.rand(size_out, hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "        self.weight_.append(np.zeros((size_out, hidden[idx - 1])))\n",
    "        self.bias.append(np.random.rand(size_out, 1))\n",
    "        self.bias_.append(np.zeros((size_out, 1)))\n",
    "        self.activations.append(np.zeros((size_out, 1)))\n",
    "        self.z.append(np.zeros((size_out, 1)))\n",
    "        \n",
    "        self.rate = rate\n",
    "        self.w_decay = w_decay\n",
    "        \n",
    "        if(hasattr(av, '__call__')):\n",
    "            self.activate = av\n",
    "        if(hasattr(av_, '__call__')):\n",
    "            self.activate_ = av_\n",
    "        if(hasattr(loss, '__call__')):\n",
    "            self.cost = loss\n",
    "        if(hasattr(loss_, '__call__')):\n",
    "            self.cost_ = loss_\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return (1 - np.exp(-(x * 2))) / (1 + np.exp(-(x * 2)))\n",
    "    \n",
    "    def activate_(self, x):\n",
    "        return 1 - np.square(self.activate(x))   \n",
    "    \n",
    "    def cost(self, y):\n",
    "        return (self.y - y) ** 2\n",
    "    \n",
    "    def cost_(self, y):\n",
    "        return (self.y - y) * 2\n",
    "    \n",
    "    def feed(self, x):\n",
    "        self.x[:] = x.reshape((x.shape[0], 1))\n",
    "        idx = 0\n",
    "        n = self.layer - 1\n",
    "        self.z[idx] = self.weight[idx].dot(self.x) + self.bias[idx]\n",
    "        self.activations[idx] = self.activate(self.z[idx])\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < n:\n",
    "            self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "            self.activations[idx] = self.activate(self.z[idx])\n",
    "            idx += 1\n",
    "        \n",
    "        self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "        self.y = self.activate(self.z[idx])\n",
    "        \n",
    "    def propagate(self, y):\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        idx = self.layer - 1\n",
    "        i_ = self.activate_(self.z[idx]) * self.cost_(y)\n",
    "        self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "        self.bias_[idx] = i_\n",
    "        c_ = self.weight[idx].T.dot(i_)\n",
    "        idx -= 1\n",
    "        \n",
    "        while idx > 0:\n",
    "            i_ = self.activate_(self.z[idx]) * c_\n",
    "            self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "            self.bias_[idx] = i_\n",
    "            c_ = self.weight[idx].T.dot(i_)\n",
    "            idx -= 1\n",
    "        \n",
    "        i_ = self.activate_(self.z[idx]) * c_\n",
    "        self.weight_[idx] = i_.dot(self.x.T)\n",
    "        self.bias_[idx] = i_\n",
    "        \n",
    "        while idx < self.layer:\n",
    "            self.weight[idx] *= 1 - self.rate * self.w_decay\n",
    "            self.weight[idx] -= self.rate * self.weight_[idx] \n",
    "            self.bias[idx] -= self.rate * self.bias_[idx]\n",
    "            idx += 1\n",
    "        \n",
    "    def heetal_w(self, cur, prev, com):\n",
    "        return np.random.randn(com, cur) * np.sqrt(2 / prev)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.y\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return (2 / (1 + np.exp(-2 * x))) - 1\n",
    "\n",
    "def tanh_(x):\n",
    "    return 1 - np.square(tanh(x))\n",
    "\n",
    "def relu(x, a = 0.01):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_(x, a = 0.01):\n",
    "    return 1 * (x > 0)\n",
    "    \n",
    "def soe(dif):\n",
    "    return np.square(dif)\n",
    "\n",
    "def soe_(dif):\n",
    "    return 2 * dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet(2, 1, [3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93877976]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('tmp/mnist.pkl.gz', 'rb') as file:\n",
    "    train_set, valid_set, test_set = pickle.load(file, encoding='iso-8859-1')\n",
    "train_x, train_y = train_set\n",
    "valid_x, valid_y = valid_set\n",
    "test_x, test_y = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ann, x, y, n = 1):\n",
    "    i = 0\n",
    "    epoch = 1\n",
    "    out = np.zeros((10, 1))\n",
    "    plot_size = (x.shape[0] * n) + 1\n",
    "    costs = np.zeros(plot_size)\n",
    "    w_ = np.zeros(plot_size)\n",
    "    b_ = np.zeros(plot_size)\n",
    "    while i < n:\n",
    "        idx = x.shape[0] - 1\n",
    "        while idx > -1:\n",
    "            ann.feed(x[idx].reshape((1, 784)))\n",
    "            out[y[idx]][0] = 1\n",
    "            costs[epoch] = ann.cost(out).sum()\n",
    "            ann.propagate(out)\n",
    "            w_[epoch] = ann.weight_[2][0][0]\n",
    "            b_[epoch] = ann.bias_[2][0][0]\n",
    "            out[y[idx]][0] = 0\n",
    "            idx -= 1\n",
    "            epoch += 1\n",
    "        i += 1\n",
    "    return (w_, b_, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigmoid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-2c246afff614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann_sigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1568\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m362\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m181\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sigmoid' is not defined"
     ]
    }
   ],
   "source": [
    "ann_sigmoid = NeuralNet(784, 10, [1568, 784, 362, 181, 64], rate=0.1, av = sigmoid, av_ = sigmoid_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
