{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "matplotlib.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# hidden : [neurons of each specific layer]\n",
    "class NeuralNet:\n",
    "    def __init__(self, size_in, size_out, hidden, rate = 0.001, w_decay = 0, av = None, loss = None):\n",
    "        self.x = np.zeros((size_in, 1), dtype=np.float64)\n",
    "        self.y = np.zeros((size_out, 1), dtype=np.float64)\n",
    "        self.weight = []\n",
    "        self.weight_ = []\n",
    "        self.bias = []\n",
    "        self.bias_ = []\n",
    "        self.z = []\n",
    "        self.activations = []\n",
    "        \n",
    "        idx = 0\n",
    "        self.layer = len(hidden) + 1\n",
    "        n = self.layer - 1\n",
    "        self.weight.append(np.random.rand(hidden[idx], size_in) * np.sqrt(2 / size_in))\n",
    "        self.weight_.append(np.zeros((hidden[idx], size_in), dtype=np.float64))\n",
    "        self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "        self.bias_.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "        self.activations.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "        self.z.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < n:\n",
    "            self.weight.append(np.random.rand(hidden[idx], hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "            self.weight_.append(np.zeros((hidden[idx], hidden[idx - 1]), dtype=np.float64))\n",
    "            self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "            self.bias_.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "            self.z.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "            self.activations.append(np.zeros((hidden[idx], 1), dtype=np.float64))\n",
    "            idx += 1\n",
    "        \n",
    "        self.weight.append(np.random.rand(size_out, hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "        self.weight_.append(np.zeros((size_out, hidden[idx - 1]), dtype=np.float64))\n",
    "        self.bias.append(np.random.rand(size_out, 1))\n",
    "        self.bias_.append(np.zeros((size_out, 1), dtype=np.float64))\n",
    "        self.activations.append(np.zeros((size_out, 1), dtype=np.float64))\n",
    "        self.z.append(np.zeros((size_out, 1), dtype=np.float64))\n",
    "        \n",
    "        self.rate = rate\n",
    "        self.w_decay = w_decay\n",
    "        \n",
    "        if av != None:\n",
    "            if(hasattr(av[0], '__call__') and  hasattr(av[1], '__call__')):\n",
    "                self.activate = av[0]\n",
    "                self.activate_ = av[1]\n",
    "                \n",
    "        if loss != None:\n",
    "            if(hasattr(loss[0], '__call__') and  hasattr(loss[1], '__call__')):\n",
    "                self.cost = loss[0]\n",
    "                self.cost_ = loss[1]\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return (1 - np.exp(-(x * 2))) / (1 + np.exp(-(x * 2)))\n",
    "    \n",
    "    def activate_(self, x):\n",
    "        return 1 - np.square(self.activate(x))   \n",
    "    \n",
    "    def cost(self, y):\n",
    "        return (self.y - y) ** 2\n",
    "    \n",
    "    def cost_(self, y):\n",
    "        return (self.y - y) * 2\n",
    "    \n",
    "    def feed(self, x):\n",
    "        self.x[:] = x.reshape((x.shape[0], 1))\n",
    "        idx = 0\n",
    "        n = self.layer - 1\n",
    "        self.z[idx] = self.weight[idx].dot(self.x) + self.bias[idx]\n",
    "        self.activations[idx] = self.activate(self.z[idx])\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < n:\n",
    "            self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "            self.activations[idx] = self.activate(self.z[idx])\n",
    "            idx += 1\n",
    "        \n",
    "        self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "        self.y = self.activate(self.z[idx])\n",
    "        \n",
    "    def propagate(self, y):\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        idx = self.layer - 1\n",
    "        i_ = self.activate_(self.z[idx]) * self.cost_(y)\n",
    "        self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "        self.bias_[idx] = i_\n",
    "        c_ = self.weight[idx].T.dot(i_)\n",
    "        idx -= 1\n",
    "        \n",
    "        while idx > 0:\n",
    "            i_ = self.activate_(self.z[idx]) * c_\n",
    "            self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "            self.bias_[idx] = i_\n",
    "            c_ = self.weight[idx].T.dot(i_)\n",
    "            idx -= 1\n",
    "        \n",
    "        i_ = self.activate_(self.z[idx]) * c_\n",
    "        self.weight_[idx] = i_.dot(self.x.T)\n",
    "        self.bias_[idx] = i_\n",
    "        \n",
    "        \n",
    "        while idx < self.layer:\n",
    "            self.weight_[idx] += self.weight[idx] * self.w_decay\n",
    "            w, b = self.update(self.weight_[idx], self.bias_[idx], idx)\n",
    "            self.weight[idx] -= w\n",
    "            self.bias[idx] -= b\n",
    "            idx += 1\n",
    "    \n",
    "    def update(self, w_, b_, idx):\n",
    "        return self.rate * w_, self.rate * b_\n",
    "    \n",
    "    def heetal_w(self, cur, prev, com):\n",
    "        return np.random.randn(com, cur) * np.sqrt(2 / prev)\n",
    "           \n",
    "    def result(self):\n",
    "        return self.y\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return (2 / (1 + np.exp(-2 * x))) - 1\n",
    "\n",
    "def tanh_(x):\n",
    "    return 1 - np.square(tanh(x))\n",
    "\n",
    "def relu(x, a = 0.01):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_(x, a = 0.01):\n",
    "    return 1 * (x > 0)\n",
    "    \n",
    "def soe(dif):\n",
    "    return np.square(dif)\n",
    "\n",
    "def soe_(dif):\n",
    "    return 2 * dif\n",
    "\n",
    "class AdaDelta:\n",
    "    def __init__(self, ann, arbitary = 1e-25, moment = 0.9):\n",
    "        self.epsilon = arbitary\n",
    "        self.moment = moment\n",
    "        self.rate = ann.rate\n",
    "        self.E = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        self.delta = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        ann.update = self\n",
    "        \n",
    "    def evaluate(self, w_, b_, idx):\n",
    "        self.E[0][idx] = self.moment * self.E[0][idx] + (1 - self.moment) * (w_ ** 2)\n",
    "        delta = self.rate * w_\n",
    "        delta /= np.sqrt(self.E[0][idx] + self.epsilon)\n",
    "        old_delta = self.delta[0][idx]\n",
    "        self.delta[0][idx] = self.moment * self.delta[0][idx] + (1 - self.moment) * (delta ** 2)\n",
    "        \n",
    "        self.E[1][idx] = self.moment * self.E[1][idx] + (1 - self.moment) * (b_ ** 2)\n",
    "        delta = self.rate * b_\n",
    "        delta /= np.sqrt(self.E[1][idx] + self.epsilon)\n",
    "        old_delta_b = self.delta[1][idx]\n",
    "        self.delta[1][idx] = self.moment * self.delta[1][idx] + (1 - self.moment) * (delta ** 2)\n",
    "        \n",
    "        w_rate = np.sqrt(old_delta + self.epsilon)\n",
    "        w_rate /= np.sqrt(self.E[0][idx] + self.epsilon)\n",
    "        \n",
    "        b_rate = np.sqrt(old_delta_b + self.epsilon)\n",
    "        b_rate /= np.sqrt(self.E[1][idx] + self.epsilon)\n",
    "        \n",
    "        return w_rate, b_rate\n",
    "        \n",
    "    def __call__(self, w_, b_, idx):\n",
    "        w_rate, b_rate = self.evaluate(w_, b_, idx)\n",
    "        return w_rate * w_, b_rate * b_\n",
    "            \n",
    "    def genParams(self, ann, is_weight = True):\n",
    "        l = ann.layer\n",
    "        idx = 0\n",
    "        while idx < l:\n",
    "            yield np.zeros(ann.weight_[idx].shape if is_weight else ann.bias_[idx].shape, dtype=np.float64)\n",
    "            idx += 1\n",
    "            \n",
    "class Adam:\n",
    "    def __init__(self, ann, arbitary = 1e-8, beta1 = 0.9, beta2 = 0.999):\n",
    "        self.epsilon = arbitary\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.rate = ann.rate\n",
    "        self.M = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        self.V = [[x for x in self.genParams(ann)], [x for x in self.genParams(ann, is_weight=False)]]\n",
    "        ann.update = self\n",
    "    \n",
    "    def __call__(self, w_, b_, idx):\n",
    "        self.M[0][idx] = self.beta1 * self.M[0][idx] + (1 - self.beta1) * w_\n",
    "        self.V[0][idx] = self.beta2 * self.V[0][idx] + (1 - self.beta2) * (w_ ** 2)\n",
    "        M_cup = self.M[0][idx] / (1 - self.beta1)\n",
    "        V_cup = self.V[0][idx] / (1 - self.beta2)\n",
    "        weight = self.rate * (M_cup / (np.sqrt(V_cup) + self.epsilon))\n",
    "        \n",
    "        self.M[1][idx] = self.beta1 * self.M[1][idx] + (1 - self.beta1) * b_\n",
    "        self.V[1][idx] = self.beta2 * self.V[1][idx] + (1 - self.beta2) * (b_ ** 2)\n",
    "        M_cup = self.M[1][idx] / (1 - self.beta1)\n",
    "        V_cup = self.V[1][idx] / (1 - self.beta2)\n",
    "        bias = self.rate * (M_cup / (np.sqrt(V_cup) + self.epsilon))\n",
    "        \n",
    "        return weight, bias\n",
    "            \n",
    "    def genParams(self, ann, is_weight = True):\n",
    "        l = ann.layer\n",
    "        idx = 0\n",
    "        while idx < l:\n",
    "            yield np.zeros(ann.weight_[idx].shape if is_weight else ann.bias_[idx].shape, dtype=np.float64)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/data-science-group-iitr/logistic-regression-simplified-9b4efe801389\n",
    "#https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plot.subplots(nrows=2, figsize=(12,9))\n",
    "\n",
    "ax0.plot(x, sg, linewidth=3)\n",
    "ax0.spines['bottom'].set_position('zero')\n",
    "ax0.set_title('Sigmoid')\n",
    "\n",
    "ax1.plot(x, sg_, linewidth=3)\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.set_title('dSigmoid')\n",
    "\n",
    "for ax in (ax0, ax1):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['left'].set_smart_bounds(True)\n",
    "    ax.spines['bottom'].set_smart_bounds(True)\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plot.subplots(nrows=2, figsize=(12,9))\n",
    "\n",
    "ax0.plot(x, th, linewidth=3)\n",
    "ax0.spines['bottom'].set_position('center')\n",
    "ax0.set_title('Tanh')\n",
    "\n",
    "ax1.plot(x, th_, linewidth=3)\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.set_title('dTanh')\n",
    "\n",
    "for ax in (ax0, ax1):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['left'].set_smart_bounds(True)\n",
    "    ax.spines['bottom'].set_smart_bounds(True)\n",
    "    ax.get_yaxis().tick_left()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plot.subplots(nrows=2, figsize=(12,9))\n",
    "\n",
    "ax0.plot(x, square, linewidth=3)\n",
    "ax0.spines['bottom'].set_position('zero')\n",
    "ax0.set_title('SoE')\n",
    "\n",
    "ax1.plot(x, square_, linewidth=3)\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.set_title('dSoE')\n",
    "\n",
    "for ax in (ax0, ax1):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['left'].set_smart_bounds(True)\n",
    "    ax.spines['bottom'].set_smart_bounds(True)\n",
    "    ax.get_yaxis().tick_left()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plot.subplots(nrows=2, figsize=(12,9))\n",
    "\n",
    "ax0.plot(x, r, linewidth=3)\n",
    "ax0.spines['bottom'].set_position('zero')\n",
    "ax0.set_title('ReLU')\n",
    "\n",
    "ax1.plot(x, r_, linewidth=3)\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.set_title('dReLU')\n",
    "\n",
    "for ax in (ax0, ax1):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['left'].set_smart_bounds(True)\n",
    "    ax.spines['bottom'].set_smart_bounds(True)\n",
    "    ax.get_yaxis().tick_left()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('tmp/mnist.pkl.gz', 'rb') as file:\n",
    "    train_set, valid_set, test_set = pickle.load(file, encoding='iso-8859-1')\n",
    "train_x, train_y = train_set\n",
    "valid_x, valid_y = valid_set\n",
    "test_x, test_y = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((10, 1))\n",
    "n = 1 # Only one training? If not change it\n",
    "plot_size = (train_x.shape[0] * n) + 1\n",
    "xaxis = np.arange(0, plot_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314049564319982"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_sigmoid = NeuralNet(784, 10, [25, 25], av = sigmoid, av_ = sigmoid_)\n",
    "AdaDelta(ann_sigmoid)\n",
    "cost_sinh, w_sinh, b_sinh = train(ann_sigmoid, train_x, train_y)\n",
    "validate(ann_sigmoid, valid_x, valid_y)\n",
    "validate(ann_sigmoid, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-95920846f31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_tanh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcost_tanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_tanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_tanh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_tanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_tanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_tanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validate' is not defined"
     ]
    }
   ],
   "source": [
    "ann_tanh = NeuralNet(784, 10, [25, 25])\n",
    "Adam(ann_tanh)\n",
    "cost_tanh, w_tanh, b_tanh = train(ann_tanh, train_x, train_y)\n",
    "validate(ann_tanh, valid_x, valid_y)\n",
    "validate(ann_tanh, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_relu = NeuralNet(784, 10, [25, 25], w_decay=0.0001, av = relu, av_ = relu_)\n",
    "AdaDelta(ann_relu)\n",
    "cost_relu, w_relu, b_relu = train(ann_relu, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8629670169697969"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 68\n",
    "#train(ann_relu, valid_x, valid_y)\n",
    "validate(ann_tanh, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ann, x, y, n = 1):\n",
    "    i = 0\n",
    "    epoch = 1\n",
    "    out = np.zeros(10)\n",
    "    plot_size = (x.shape[0] * n) + 1\n",
    "    costs = np.zeros(plot_size)\n",
    "    w_ = np.zeros(plot_size)\n",
    "    b_ = np.zeros(plot_size)\n",
    "    while i < n:\n",
    "        idx = x.shape[0] - 1\n",
    "        while idx > -1:\n",
    "            ann.feed(x[idx])\n",
    "            out[y[idx]] = 1\n",
    "            costs[epoch] = ann.cost(out).sum()\n",
    "            ann.propagate(out)\n",
    "            w_[epoch] = ann.weight_[2][0][0]\n",
    "            b_[epoch] = ann.bias_[2][0][0]\n",
    "            out[y[idx]] = 0\n",
    "            idx -= 1\n",
    "            epoch += 1\n",
    "        i += 1\n",
    "    return (w_, b_, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(ann, x, y):\n",
    "    idx = x.shape[0] - 1\n",
    "    sum = 0.0\n",
    "    out = np.zeros((10, 1))\n",
    "    while idx > -1:\n",
    "        ann.feed(x[idx])\n",
    "        out[y[idx]] = 1\n",
    "        sum += ann.cost(out.reshape((out.shape[0], 1))).sum()\n",
    "        out[y[idx]] = 0\n",
    "        idx -=  1\n",
    "    sum /= x.shape[0]\n",
    "    return 1 - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-463a7c81299a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-463a7c81299a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    y[test_y[idx] = 1\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "idx = test_x.shape[0] - 1\n",
    "sum = 0.0\n",
    "while idx > -1:\n",
    "    ann_sigmoid.feed(test_x[idx])\n",
    "    y[test_y[idx]] = 1\n",
    "    sum = sum + ann.cost(y).sum()\n",
    "    y[test_y[idx]][0] = 0\n",
    "    idx = idx - 1\n",
    "sum = sum / test_x.shape[0]\n",
    "print(1 - sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax0 = plot.subplots(nrows=1, figsize=(12, 9))\n",
    "ax0.plot(xaxis[::100], cost_sinh[::100], linewidth=1, label='sinh with 0.1 Learning Rate')\n",
    "ax0.plot(xaxis[::100], cost_tanh[::100], linewidth=1, label='tanh with 0.1 Learning Rate')\n",
    "ax0.plot(xaxis[::100], cost_relu[::100], linewidth=1, label='relu with 0.0001 Learning Rate')\n",
    "ax0.spines['bottom'].set_position('zero')\n",
    "ax0.set_title('Traning Costs')\n",
    "ax0.legend()\n",
    "\n",
    "ax0.spines['top'].set_visible(False)\n",
    "ax0.spines['right'].set_visible(False)\n",
    "ax0.get_xaxis().tick_bottom()\n",
    "ax0.spines['left'].set_smart_bounds(True)\n",
    "ax0.spines['left'].set_position('zero')\n",
    "ax0.spines['bottom'].set_smart_bounds(True)\n",
    "ax0.get_yaxis().tick_left()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2TkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "class FixedOrderFormatter(ScalarFormatter):\n",
    "    \"\"\"Formats axis ticks using scientific notation with a constant order of \n",
    "    magnitude\"\"\"\n",
    "    def __init__(self, order_of_mag=0, useOffset=True, useMathText=False):\n",
    "        self._order_of_mag = order_of_mag\n",
    "        ScalarFormatter.__init__(self, useOffset=useOffset, \n",
    "                                 useMathText=useMathText)\n",
    "    def _set_orderOfMagnitude(self, range):\n",
    "        \"\"\"Over-riding this to avoid having orderOfMagnitude reset elsewhere\"\"\"\n",
    "        self.orderOfMagnitude = self._order_of_mag\n",
    "\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "\n",
    "\n",
    "fig = plot.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "rpr_dW = w_sinh[:60]\n",
    "rpr_dB = b_sinh[:60]\n",
    "rpr_costs = cost_sinh[:60]\n",
    "\n",
    "for k in range(0, rpr_dW.size, 1):\n",
    "    ax.plot(rpr_dW[:k], rpr_dB[:k], rpr_costs[:k])\n",
    "    \n",
    "    #ax.set_xlim3d(-0.4, 0.4)\n",
    "    #ax.set_ylim3d(-0.4, 0.4)\n",
    "    #ax.set_zlim3d(0, 100)\n",
    "    ax.xaxis.set_label_text('dW')\n",
    "    ax.yaxis.set_label_text('dB')\n",
    "    ax.zaxis.set_label_text('Costs')\n",
    "    ax.xaxis.label.set_fontsize(12)\n",
    "    ax.yaxis.label.set_fontsize(12)\n",
    "    ax.zaxis.label.set_fontsize(12)\n",
    "    ax.xaxis.set_major_formatter(FixedOrderFormatter(0))\n",
    "    ax.yaxis.set_major_formatter(FixedOrderFormatter(0))\n",
    "    ax.zaxis.set_major_formatter(FixedOrderFormatter(0))\n",
    "    plot.draw()\n",
    "    plot.pause(0.05)\n",
    "    if k != rpr_dW.size - 1:\n",
    "        ax.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot.figure(figsize=(12, 9))\n",
    "ax = fig.gca(projection = '3d')\n",
    "ax.set_title('Gradient Plane')\n",
    "#ax.plot(w_tanh[::100], b_tanh[::100], np.vstack((cost_relu[::100], xaxis[::100])), label = 'Tanh')\n",
    "#ax.plot(w_sinh[::100], b_sinh[::100], np.vstack((cost_relu[::100], xaxis[::100])), label = 'Sinh')\n",
    "ax.plot_wireframe(w_relu[::100], b_relu[::100], np.vstack((cost_relu[::100], xaxis[::100])), label = 'Relu')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll, year, rc, semester, external, prev_performance\n",
    "# activities, internal, external\n",
    "\n",
    "activities = roll + academic_progress + attendance + semester + external + prev_performance\n",
    "internal = roll + acdaemic_progress + attendance + semester + external + prev_performance\n",
    "external = roll + academic_progress + attendance + semester + external + prev_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nero = NeuralNet(6, 3, [25, 25], rate=0.01, w_decay= 0.1, av= relu, av_=relu_)\n",
    "nero.weight_[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
