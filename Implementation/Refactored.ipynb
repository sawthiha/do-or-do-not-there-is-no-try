{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden : [neurons of each specific layer]\n",
    "class NeuralNet:\n",
    "    def __init__(self, size_in, size_out, hidden, rate = 0.1, w_decay = 0, av = None, av_ = None, loss = None, loss_ = None):\n",
    "        self.x = np.zeros((size_in, 1), dtype=np.float64)\n",
    "        self.y = np.zeros((size_out, 1), dtype=np.float64)\n",
    "        self.weight = []\n",
    "        self.weight_ = []\n",
    "        self.bias = []\n",
    "        self.bias_ = []\n",
    "        self.z = []\n",
    "        self.activations = []\n",
    "        \n",
    "        idx = 0\n",
    "        self.layer = len(hidden) + 1\n",
    "        n = self.layer - 1\n",
    "        self.weight.append(np.random.rand(hidden[idx], size_in) * np.sqrt(2 / size_in))\n",
    "        self.weight_.append(np.zeros((hidden[idx], size_in)))\n",
    "        self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "        self.bias_.append(np.zeros((hidden[idx], 1)))\n",
    "        self.activations.append(np.zeros((hidden[idx], 1)))\n",
    "        self.z.append(np.zeros((hidden[idx], 1)))\n",
    "        \n",
    "        idx += 1\n",
    "        while idx < n:\n",
    "            self.weight.append(np.random.rand(hidden[idx], hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "            self.weight_.append(np.zeros((hidden[idx], hidden[idx - 1])))\n",
    "            self.bias.append(np.random.rand(hidden[idx], 1))\n",
    "            self.bias_.append(np.zeros((hidden[idx], 1)))\n",
    "            self.z.append(np.zeros((hidden[idx], 1)))\n",
    "            self.activations.append(np.zeros((hidden[idx], 1)))\n",
    "            idx += 1\n",
    "        \n",
    "        self.weight.append(np.random.rand(size_out, hidden[idx - 1]) * np.sqrt(2 / hidden[idx - 1]))\n",
    "        self.weight_.append(np.zeros((size_out, hidden[idx - 1])))\n",
    "        self.bias.append(np.random.rand(size_out, 1))\n",
    "        self.bias_.append(np.zeros((size_out, 1)))\n",
    "        self.activations.append(np.zeros((size_out, 1)))\n",
    "        self.z.append(np.zeros((size_out, 1)))\n",
    "        \n",
    "        self.rate = rate\n",
    "        self.w_decay = w_decay\n",
    "        \n",
    "        if(hasattr(av, '__call__')):\n",
    "            self.activate = av\n",
    "        if(hasattr(av_, '__call__')):\n",
    "            self.activate_ = av_\n",
    "        if(hasattr(loss, '__call__')):\n",
    "            self.cost = loss\n",
    "        if(hasattr(loss_, '__call__')):\n",
    "            self.cost_ = loss_\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return (1 - np.exp(-(x * 2))) / (1 + np.exp(-(x * 2)))\n",
    "    \n",
    "    def activate_(self, x):\n",
    "        return 1 - np.square(self.activate(x))   \n",
    "    \n",
    "    def cost(self, y):\n",
    "        return (self.y - y) ** 2\n",
    "    \n",
    "    def cost_(self, y):\n",
    "        return (self.y - y) * 2\n",
    "    \n",
    "    def feed(self, x):\n",
    "        self.x[:] = x.reshape((x.shape[0], 1))\n",
    "        idx = 0\n",
    "        n = self.layer - 1\n",
    "        self.z[idx] = self.weight[idx].dot(self.x) + self.bias[idx]\n",
    "        self.activations[idx] = self.activate(self.z[idx])\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < n:\n",
    "            self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "            self.activations[idx] = self.activate(self.z[idx])\n",
    "            idx += 1\n",
    "        \n",
    "        self.z[idx] = self.weight[idx].dot(self.activations[idx - 1]) + self.bias[idx]\n",
    "        self.y = self.activate(self.z[idx])\n",
    "        \n",
    "    def propagate(self, y):\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        idx = self.layer - 1\n",
    "        i_ = self.activate_(self.z[idx]) * self.cost_(y)\n",
    "        self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "        self.bias_[idx] = i_\n",
    "        c_ = self.weight[idx].T.dot(i_)\n",
    "        idx -= 1\n",
    "        \n",
    "        while idx > 0:\n",
    "            i_ = self.activate_(self.z[idx]) * c_\n",
    "            self.weight_[idx] = i_.dot(self.activations[idx - 1].T)\n",
    "            self.bias_[idx] = i_\n",
    "            c_ = self.weight[idx].T.dot(i_)\n",
    "            idx -= 1\n",
    "        \n",
    "        i_ = self.activate_(self.z[idx]) * c_\n",
    "        self.weight_[idx] = i_.dot(self.x.T)\n",
    "        self.bias_[idx] = i_\n",
    "        \n",
    "        while idx < self.layer:\n",
    "            self.weight[idx] *= 1 - self.rate * self.w_decay\n",
    "            self.weight[idx] -= self.rate * self.weight_[idx] \n",
    "            self.bias[idx] -= self.rate * self.bias_[idx]\n",
    "            idx += 1\n",
    "        \n",
    "    def heetal_w(self, cur, prev, com):\n",
    "        return np.random.randn(com, cur) * np.sqrt(2 / prev)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.y\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return (2 / (1 + np.exp(-2 * x))) - 1\n",
    "\n",
    "def tanh_(x):\n",
    "    return 1 - np.square(tanh(x))\n",
    "\n",
    "def relu(x, a = 0.01):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_(x, a = 0.01):\n",
    "    return 1 * (x > 0)\n",
    "    \n",
    "def soe(dif):\n",
    "    return np.square(dif)\n",
    "\n",
    "def soe_(dif):\n",
    "    return 2 * dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet(2, 1, [3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('tmp/mnist.pkl.gz', 'rb') as file:\n",
    "    train_set, valid_set, test_set = pickle.load(file, encoding='iso-8859-1')\n",
    "train_x, train_y = train_set\n",
    "valid_x, valid_y = valid_set\n",
    "test_x, test_y = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ann, x, y, n = 1):\n",
    "    i = 0\n",
    "    epoch = 1\n",
    "    out = np.zeros(10)\n",
    "    plot_size = (x.shape[0] * n) + 1\n",
    "    costs = np.zeros(plot_size)\n",
    "    w_ = np.zeros(plot_size)\n",
    "    b_ = np.zeros(plot_size)\n",
    "    while i < n:\n",
    "        idx = x.shape[0] - 1\n",
    "        while idx > -1:\n",
    "            ann.feed(x[idx])\n",
    "            out[y[idx]] = 1\n",
    "            costs[epoch] = ann.cost(out).sum()\n",
    "            ann.propagate(out)\n",
    "            w_[epoch] = ann.weight_[2][0][0]\n",
    "            b_[epoch] = ann.bias_[2][0][0]\n",
    "            out[y[idx]] = 0\n",
    "            idx -= 1\n",
    "            epoch += 1\n",
    "        i += 1\n",
    "    return (w_, b_, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_sigmoid = NeuralNet(784, 10, [25, 25], rate=0.1, av = sigmoid, av_ = sigmoid_)\n",
    "dW, dB, costs_sigmoid = train(ann_sigmoid, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2TkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "\n",
    "fig = plot.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "rpr_dW = dW[:60]\n",
    "rpr_dB = dB[:60]\n",
    "rpr_costs = costs_sigmoid[:60]\n",
    "\n",
    "for k in range(0, rpr_dW.size, 1):\n",
    "    ax.plot(rpr_dW[:k], rpr_dB[:k], rpr_costs[:k])\n",
    "    ax.set_xlim3d(-0.4, 0.4)\n",
    "    ax.set_ylim3d(-0.4, 0.4)\n",
    "    ax.set_zlim3d(0, 100)\n",
    "    ax.set_xlabel('dW')\n",
    "    ax.set_ylabel('dB')\n",
    "    ax.set_zlabel('C')\n",
    "    plot.draw()\n",
    "    plot.pause(0.05)\n",
    "    if k != rpr_dW.size - 1:\n",
    "        ax.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
